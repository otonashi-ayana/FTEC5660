{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f6eb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "GEMINI_VERTEX_API_KEY = userdata.get('VERTEX_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e9bf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "debug_enabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188d7f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import mimetypes\n",
    "import logging\n",
    "\n",
    "# Helper function to read and encode image\n",
    "def image_to_base64(img_path):\n",
    "    with open(img_path, \"rb\") as img_file:\n",
    "        return base64.b64encode(img_file.read()).decode('utf-8')\n",
    "\n",
    "# Helper function to encode local file to Base64 Data URL\n",
    "def get_image_data_url(image_path):\n",
    "    # Guess the mime type (e.g., image/png, image/jpeg) based on file extension\n",
    "    mime_type, _ = mimetypes.guess_type(image_path)\n",
    "    if mime_type is None:\n",
    "        mime_type = \"image/png\" # Default fallback\n",
    "\n",
    "    encoded_string = image_to_base64(image_path)\n",
    "\n",
    "    # Construct the Data URL\n",
    "    return f\"data:{mime_type};base64,{encoded_string}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a538d4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "for h in logger.handlers[:]:\n",
    "    logger.removeHandler(h)\n",
    "\n",
    "file_handler = logging.FileHandler(\"output.log\", encoding=\"utf-8\",mode=\"w\")\n",
    "file_handler.setLevel(logging.INFO)\n",
    "file_handler.setFormatter(logging.Formatter(\"%(asctime)s - %(message)s\"))\n",
    "\n",
    "console_handler = logging.StreamHandler(sys.stdout)\n",
    "console_handler.setLevel(logging.INFO)\n",
    "console_handler.setFormatter(logging.Formatter(\"%(message)s\"))\n",
    "\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "class LoggerWriter:\n",
    "    def __init__(self, level_func):\n",
    "        self.level_func = level_func\n",
    "    def write(self, message):\n",
    "        message = message.strip()\n",
    "        if message:\n",
    "            self.level_func(message)\n",
    "    def flush(self):\n",
    "        pass\n",
    "\n",
    "sys.stdout = LoggerWriter(logger.info)\n",
    "sys.stderr = LoggerWriter(logger.error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd3627d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "image_folder_path = \"./receipts\"\n",
    "image_data_urls = []\n",
    "for image_path in os.listdir(image_folder_path):\n",
    "    if os.path.splitext(image_path.lower())[1] in [\".jpg\", \".jpeg\", \".png\", \".bmp\"]:\n",
    "        image_data_urls.append(get_image_data_url(os.path.join(image_folder_path, image_path)))\n",
    "print(f\"Found {len(image_data_urls)} images for processing.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778647cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    api_key=GEMINI_VERTEX_API_KEY, # Ensure this key is set in Colab secrets\n",
    "    temperature=0,\n",
    "    vertexai=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0338532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import fields\n",
    "import json\n",
    "from typing import List, Optional\n",
    "from langchain_core.messages import BaseMessage\n",
    "import re\n",
    "\n",
    "\n",
    "def safe_invoke(model, cls, input: str, config: dict = None, stop: list = None, retries: int = 3) -> str:\n",
    "    for attempt in range(1, retries + 1):\n",
    "        try:\n",
    "            response = model.invoke(input, config=config, stop=stop)\n",
    "            content = response.content.strip()\n",
    "            content = re.sub(r\"^```(?:json)?\\s*|\\s*```$\", \"\", content.strip())\n",
    "            data = json.loads(content)\n",
    "            field_names = {f.name for f in fields(cls)}\n",
    "            filtered_data = {k: v for k, v in data.items() if k in field_names}\n",
    "            missing = field_names - filtered_data.keys()\n",
    "            if missing:\n",
    "                raise ValueError(f\"Missing fields: {missing}\")\n",
    "            if debug_enabled:\n",
    "                print(f\"[safe_invoke] response: {json.dumps(filtered_data, indent=2, ensure_ascii=False)}\")\n",
    "            return filtered_data\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"[safe_invoke:{attempt}] JSON decode error: {str(e)}. Response content: {response.content}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[safe_invoke:{attempt}] Error during LLM invocation: {str(e)}\")\n",
    "    return {f.name: None for f in fields(cls)}\n",
    "\n",
    "def safe_invoke_v2(\n",
    "    model,\n",
    "    cls,\n",
    "    messages: List[BaseMessage],\n",
    "    config: Optional[dict] = None,\n",
    "    stop: Optional[list] = None,\n",
    "    retries: int = 3,\n",
    ") -> dict:\n",
    "    if not isinstance(messages, list):\n",
    "        raise TypeError(\"safe_invoke_v2 expects `messages` to be a list of BaseMessage\")\n",
    "    field_names = {f.name for f in fields(cls)}\n",
    "    for attempt in range(1, retries + 1):\n",
    "        try:\n",
    "            response = model.invoke(messages, config=config, stop=stop)\n",
    "            # response.content should still be text (JSON string)\n",
    "            content = response.content.strip()\n",
    "            content = re.sub(r\"^```(?:json)?\\s*|\\s*```$\", \"\", content.strip())\n",
    "            data = json.loads(content)\n",
    "            filtered_data = {k: v for k, v in data.items() if k in field_names}\n",
    "            missing = field_names - filtered_data.keys()\n",
    "            if missing:\n",
    "                raise ValueError(f\"Missing fields: {missing}\")\n",
    "            if debug_enabled:\n",
    "                print(\n",
    "                    f\"[safe_invoke_mm_v2] response:\\n\"\n",
    "                    f\"{json.dumps(filtered_data, indent=2, ensure_ascii=False)}\"\n",
    "                )\n",
    "            return filtered_data\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\n",
    "                f\"[safe_invoke_mm_v2:{attempt}] JSON decode error: {str(e)}\\n\"\n",
    "                f\"Raw content:\\n{content}\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"[safe_invoke_mm_v2:{attempt}] Error during LLM invocation: {str(e)}\")\n",
    "    # fallback: all fields set to None\n",
    "    return {f.name: None for f in fields(cls)}\n",
    "\n",
    "def describe_schema(cls):\n",
    "    lines = [\"Your response **must** be a JSON object with the following format:\"]\n",
    "    for f in fields(cls):\n",
    "        if f.name.startswith(\"template_\"):\n",
    "            continue\n",
    "        desc = f.metadata.get(\"description\", \"\")\n",
    "        lines.append(f'- {f.name} ({f.type.__name__}): {desc}')\n",
    "    if hasattr(cls, \"output_format\"):\n",
    "        lines.append(f\"Here is an example of the expected output format:{cls.output_format}\")\n",
    "    return \"\\n\".join(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5660a3",
   "metadata": {},
   "source": [
    "Define Tool functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da1a530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def safe_exec(code: str, context: dict):\n",
    "    tree = ast.parse(code)\n",
    "    # for node in ast.walk(tree):\n",
    "    #     if not isinstance(node, ALLOWED_NODES):\n",
    "    #         raise ValueError(f\"Illegal node: {type(node)}\")\n",
    "    local_env = {}\n",
    "    exec(code, {}, local_env)\n",
    "    result = local_env[\"compute\"](context)\n",
    "    print(f\"[safe_exec]---------------\\n{context}\\nresult:\\n{json.dumps(result,indent=4)}\\n----------------\")\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025f0633",
   "metadata": {},
   "source": [
    "Define Agent State Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87d5aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, List\n",
    "class AgentState(TypedDict):\n",
    "    next_action: str\n",
    "    plan_desc: str\n",
    "    user_query: str\n",
    "    images_data: List[str] # images_data_urls[\"data:{mime_type};base64,{encoded_string}\",...]\n",
    "    receipt_results: List[dict]\n",
    "    answer: str\n",
    "    \n",
    "# 1. Define State for the Subgraph (Single Image Processing)\n",
    "class ImageState(TypedDict):\n",
    "    plan_desc: str\n",
    "    user_query: str\n",
    "    analysis_code: str  # Add this field\n",
    "    image_data: str # \"data:{mime_type};base64,{encoded_string}\"\n",
    "    identification: dict\n",
    "    sub_result: str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce359e1",
   "metadata": {},
   "source": [
    "Define LLM response format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519d2d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "\n",
    "@dataclass\n",
    "class PlanningOutput:\n",
    "    thought: str = field(metadata={\"description\": \"One sentence thought process.\"})\n",
    "    next_action: str = field(metadata={\"description\": \"The next action phase to take. Must be one of these words: execute, interrupt.\"})\n",
    "    plan_desc: str = field(metadata={\"description\": \"A one sentence description about how to complete the task. If action is 'interrupt', leave 'None'.\"})\n",
    "    output_format = \"\"\"\n",
    "{\n",
    "  \"thought\": <string>,\n",
    "  \"next_action\": \"<string>,\n",
    "  \"plan_desc\": <string>\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "@dataclass\n",
    "class IdentifyOutput:\n",
    "    items: List[dict] = field(metadata={\"description\": \"List of items with name, quantity, line_subtotal, discount_amount.\"})\n",
    "    subtotal: float = field(metadata={\"description\": \"The subtotal amount.\"})\n",
    "    rounding: float = field(metadata={\"description\": \"The rounding adjustment amount.\"})\n",
    "    output_format = \"\"\"\n",
    "{\n",
    "  \"items\": [\n",
    "    {\n",
    "      \"name\": <string>,\n",
    "      \"quantity\": <int>,\n",
    "      \"line_subtotal\": <float>,\n",
    "      \"discount_amount\": <negative float>,\n",
    "    },\n",
    "    ...\n",
    "  ],\n",
    "  \"subtotal\": <float>,\n",
    "  \"rounding\": <negative float>\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "@dataclass\n",
    "class AnalyzeOutput:\n",
    "    thought: str = field(metadata={\"description\": \"One sentence thought process.\"})\n",
    "    code: str = field(\n",
    "        metadata={\"description\": \"Python code string defining def compute(receipt): answering the query.\"}\n",
    "    )\n",
    "    output_format = \"\"\"\n",
    "{\n",
    "  \"thought\": <string>\n",
    "  \"code\": <string>\n",
    "}\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf84dea",
   "metadata": {},
   "source": [
    "Define Graph nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398aa8cf",
   "metadata": {},
   "source": [
    "1. Subgraph nodes for Image processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3560e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.types import Command\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "def identify_node(state: ImageState):\n",
    "    print(\"[Identify] Identifying image content...\")\n",
    "    IDENTIFY_PROMPT = \"\"\"\n",
    "You are the identify module of an agent that processes receipt images and handle questions.\n",
    "[Task]\n",
    "Given an image of a retail receipt, extract ONLY the information required for bookkeeping.\n",
    "[Extraction Rules]\n",
    "- The price on the right of item name is `line_subtotal`, it is the amount **BEFORE** discount for an item. You MUST NOT add it with discount amount mistakenly\n",
    "- Discounts must be recorded as negative amounts.\n",
    "- If no discount for one item, set discount_amount to 0.\n",
    "- If quantity is not explicitly shown, set quantity = 1.\n",
    "- Ignore loyalty points, card numbers, device numbers, cashier info, store address, timestamps.\n",
    "- Amounts must be numeric values without currency symbols.\n",
    "[Warning]\n",
    "{schema}\n",
    "Do NOT include explanations, comments, or any text outside the JSON.\n",
    "Do NOT infer or guess missing information.\n",
    "If a value is not explicitly shown on the receipt, set it to null.\n",
    "\"\"\"\n",
    "    messages = [\n",
    "        HumanMessage(\n",
    "            content=[\n",
    "                {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": IDENTIFY_PROMPT.format(\n",
    "                        schema=describe_schema(IdentifyOutput)\n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": state[\"image_data\"]\n",
    "                    },\n",
    "                },\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "    response = safe_invoke_v2(llm, IdentifyOutput, messages=messages)\n",
    "    return {\"identification\": response}\n",
    "\n",
    "def execute_node(state: ImageState):\n",
    "    print(\"[Execute] Extracting data from receipt...\")\n",
    "    identification = state[\"identification\"]\n",
    "    analysis_code = state.get(\"analysis_code\", \"\")\n",
    "    try:\n",
    "        exec_result = safe_exec(analysis_code, identification)\n",
    "    except Exception as e:\n",
    "        print(f\"[Analyze] Error executing code: {e}\")\n",
    "        exec_result = None\n",
    "\n",
    "    return {\"sub_result\": exec_result}\n",
    "\n",
    "def validate_node(state: ImageState):\n",
    "    print(\"[Validate] Validating identification and analysis...\")\n",
    "    # Logic: Check if total matches sum of items\n",
    "    next_action = \"\" # identify \\ analyze \\ \n",
    "    if next_action == \"identify\":\n",
    "        return Command(\n",
    "            goto=\"identify\"\n",
    "        )\n",
    "    elif next_action == \"analyze\":\n",
    "        return Command(\n",
    "            goto=\"analyze\"\n",
    "        )\n",
    "    return {\"sub_result\": state[\"sub_result\"]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6fabb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "receipt_builder = StateGraph(ImageState)\n",
    "receipt_builder.add_node(\"identify\", identify_node)\n",
    "receipt_builder.add_node(\"execute\", execute_node)\n",
    "receipt_builder.add_node(\"validate\", validate_node)\n",
    "receipt_builder.add_edge(\"identify\", \"execute\")\n",
    "receipt_builder.add_edge(\"execute\", END)\n",
    "# receipt_builder.add_edge(\"analyze\", \"validate\")\n",
    "# receipt_builder.add_edge(\"validate\", END) # if validate node doesn't use goto, it goes to END\n",
    "receipt_builder.set_entry_point(\"identify\")\n",
    "\n",
    "receipt_processing_graph = receipt_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ef7615",
   "metadata": {},
   "source": [
    "2. Agent graph nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe76c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_node(state: AgentState):\n",
    "    print(\"[Plan] deciding next action and plan description\")\n",
    "    prompt = f\"\"\"\n",
    "You are the plan module of an agent that processes receipt images and handles questions.\n",
    "[Query from User]\n",
    "{state[\"user_query\"]}\n",
    "[Ability Boundary]\n",
    "You can only handle these queries:\n",
    "1. Total money spent for the receipts.\n",
    "2. Amount of money should have been spent without the discount.\n",
    "[Task]\n",
    "Decide the next action and a brief plan description to handle user's query.\n",
    "If the query is irrelevant to the ability boundary, set action to \"interrupt\" and plan_desc to \"None\".\n",
    "[Warning]\n",
    "{describe_schema(PlanningOutput)}\n",
    "\"\"\"\n",
    "    response = safe_invoke(llm, PlanningOutput, prompt)\n",
    "    return {\n",
    "        \"next_action\": response[\"next_action\"],\n",
    "        \"plan_desc\": response[\"plan_desc\"]\n",
    "    }\n",
    "    \n",
    "async def analyze_node(state: AgentState):\n",
    "    print(\"[Analyze] Generating analysis code...\")\n",
    "    user_query = state.get(\"user_query\", \"\")\n",
    "    plan_desc = state.get(\"plan_desc\", \"\")\n",
    "\n",
    "    # Generate the analysis code ONCE for all receipts\n",
    "    prompt = f\"\"\"\n",
    "You are the analysis module of an agent that processes receipt images and handle questions.\n",
    "[Task]\n",
    "Generate a valid Python code snippet that defines a function `compute(receipt)` returning a numeric result.\n",
    "The function will receive the receipt data as a dictionary argument.\n",
    "\n",
    "[User Query]\n",
    "{user_query}\n",
    "\n",
    "[Basic Plan]\n",
    "{plan_desc}\n",
    "\n",
    "[Receipt Data Structure]\n",
    "The `receipt` argument is a dictionary with the following fields:\n",
    "- `items` (list[dict]): A list of items purchased. Each item dict has:\n",
    "    - `name` (str): Name of the item.\n",
    "    - `quantity` (int): Quantity purchased.\n",
    "    - `line_subtotal` (float): The price of the line item **BEFORE** any discount.\n",
    "    - `discount_amount` (float): The discount applied to this item (negative value).\n",
    "- `subtotal` (float): The total sum before rounding.\n",
    "- `rounding` (float): The rounding adjustment.\n",
    "\n",
    "[Requirements]\n",
    "{describe_schema(AnalyzeOutput)}\n",
    "- The code must define exactly one function `compute(receipt)` taking `receipt` as input.\n",
    "- The function must return a single numeric value (int or float).\n",
    "- Use standard Python operations (sum, list comprehension, basic math).    \n",
    "- No imports allowed.\n",
    "- Do not include comments, docstrings, or explanations.\n",
    "\n",
    "[Examples]\n",
    "User query: \"How much would I have had to pay without the discount?\"\n",
    "def compute(receipt):\n",
    "    # Sum line_subtotal (price before discount) for all items\n",
    "    return sum(item.get('line_subtotal', 0) for item in receipt.get('items', []))\n",
    "\n",
    "User query: \"How much money did I spend in total for these bills?\"\n",
    "def compute(receipt):\n",
    "    return receipt.get('subtotal', 0) + receipt.get('rounding', 0)\n",
    "\"\"\"\n",
    "    response = safe_invoke(llm, AnalyzeOutput, prompt)\n",
    "    analysis_code = response[\"code\"]\n",
    "    print(f\"[Analyze] Generated Analysis Code:\\n{analysis_code}\")\n",
    "\n",
    "    print(\"[Analyze] Processing images in parallel...\")\n",
    "    images = state.get(\"images_data\", [])\n",
    "    # Pass the generated code to each subgraph instance\n",
    "    inputs = [\n",
    "        {\n",
    "            \"image_data\": img, \n",
    "            \"user_query\": state[\"user_query\"], \n",
    "            \"plan_desc\": state[\"plan_desc\"],\n",
    "            \"analysis_code\": analysis_code\n",
    "        } \n",
    "        for img in images\n",
    "    ]\n",
    "    # Run the subgraph in parallel for all images\n",
    "    # .abatch executes the graph for each input concurrently\n",
    "    results = await receipt_processing_graph.abatch(inputs)\n",
    "    # Extract final results from the subgraph outputs\n",
    "    receipt_data = [r[\"sub_result\"] for r in results if \"sub_result\" in r]\n",
    "    print(f\"  Received {len(receipt_data)} processed results.\")\n",
    "    total_sum = sum(float(r.get(\"sub_result\", 0)) if r.get(\"sub_result\") is not None else 0 for r in results)\n",
    "    print(f\"  Final Integration: Total Sum = {total_sum}\")\n",
    "    return {\"receipt_results\": receipt_data,\n",
    "            \"answer\": total_sum}\n",
    "  \n",
    "def end_node(state):\n",
    "  if state[\"next_action\"] == \"interrupt\":\n",
    "      print(\"The query is invalid.\")\n",
    "  else:\n",
    "      print(\"Completed successfully.\")\n",
    "  return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cca6cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_builder = StateGraph(AgentState)\n",
    "agent_builder.add_node(\"plan\", plan_node)\n",
    "agent_builder.add_node(\"analyze\", analyze_node)\n",
    "agent_builder.add_node(\"end\", end_node)\n",
    "agent_builder.set_entry_point(\"plan\")\n",
    "\n",
    "def routing_plan(state):\n",
    "    if state[\"next_action\"] == \"interrupt\":\n",
    "        return \"end\"\n",
    "    return \"analyze\"\n",
    "\n",
    "agent_builder.add_conditional_edges(\"plan\", routing_plan)\n",
    "agent_builder.add_edge(\"analyze\", \"end\")\n",
    "\n",
    "agent_graph = agent_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61d74ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_query(answer, ground_truth_costs):\n",
    "    # Convert string to float if necessary\n",
    "    if isinstance(answer, str):\n",
    "        answer = float(answer)\n",
    "\n",
    "    # Calculate the ground truth sum once for clarity\n",
    "    expected_total = sum(ground_truth_costs)\n",
    "\n",
    "    # Check if the answer is within +/- $2 of the expected total\n",
    "    assert abs(answer - expected_total) <= 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beddcd00",
   "metadata": {},
   "source": [
    "Run the following code block to evaluate query 1:\n",
    "> How much money did I spend in total for these bills?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85ef906",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = {\n",
    "    \"user_query\": \"How much money did I spend in total for these bills?\",\n",
    "    \"images_data\": image_data_urls\n",
    "}\n",
    "result_1 = await agent_graph.ainvoke(user_input, config={\"max_concurrency\": 3})\n",
    "query_1_costs = [394.7, 316.1, 140.8, 514.0, 102.3, 190.8, 315.6] # do not modify this\n",
    "print(result_1['receipt_results'])\n",
    "query1_answer = result_1['answer']\n",
    "test_query(query1_answer, query_1_costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ef180c",
   "metadata": {},
   "source": [
    "Run the following code block to evaluate query 2:\n",
    "> How much would I have had to pay without the discount?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d590c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = {\n",
    "    \"user_query\": \"How much would I have had to pay without the discount?\",\n",
    "    \"images_data\": image_data_urls\n",
    "}\n",
    "result_2 = await agent_graph.ainvoke(user_input, config={\"max_concurrency\": 3})\n",
    "query_2_costs = [480.20, 392.20, 160.10, 590.80, 107.70, 221.20, 396.00] # do not modify this\n",
    "print(result_2['receipt_results'])\n",
    "query2_answer = result_2['answer']\n",
    "test_query(query2_answer, query_2_costs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ftec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
