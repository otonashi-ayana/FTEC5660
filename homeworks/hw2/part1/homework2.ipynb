{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFaf7VErZ1Bf"
      },
      "source": [
        "# Homework 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3g3k3W-qfAv"
      },
      "source": [
        "# Set up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUav-7KdaY_W"
      },
      "source": [
        "## Setup your API key\n",
        "\n",
        "To run the following cell, your API key must be stored it in a Colab Secret named `VERTEX_API_KEY`.\n",
        "\n",
        "\n",
        "1.   Look for the key icon on the left panel of your colab.\n",
        "2.   Under `Name`, create `VERTEX_API_KEY`.\n",
        "3. Copy your key to `Value`.\n",
        "\n",
        "If you cannot use VERTEX_API_KEY, you can use deepseek models via `DEEPSEEK_API_KEY`. It does not affect your score.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueILmCPHci9v"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "GEMINI_VERTEX_API_KEY = userdata.get('VERTEX_API_KEY')\n",
        "# DEEPSEEK_API_KEY = userdata.get('DEEPSEEK_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2akmVn9LODIu",
        "outputId": "36bb6f9a-4286-4d5d-983e-788d8c3c055b"
      },
      "outputs": [],
      "source": [
        "# =====================================================\n",
        "#  Load and display all CV PDFs in order\n",
        "# =====================================================\n",
        "import os\n",
        "from markitdown import MarkItDown\n",
        "\n",
        "cv_dir = \"downloaded_cvs\"\n",
        "\n",
        "# Initialize MarkItDown\n",
        "md = MarkItDown(enable_plugins=False)\n",
        "\n",
        "# Collect and sort PDFs numerically\n",
        "pdf_files = sorted(\n",
        "    [f for f in os.listdir(cv_dir) if f.lower().endswith(\".pdf\")],\n",
        "    key=lambda x: int(\"\".join(filter(str.isdigit, x)))  # CV_1.pdf â†’ 1\n",
        ")\n",
        "\n",
        "all_cvs = []\n",
        "\n",
        "for pdf_name in pdf_files:\n",
        "    pdf_path = os.path.join(cv_dir, pdf_name)\n",
        "    result = md.convert(pdf_path)\n",
        "\n",
        "    all_cvs.append({\n",
        "        \"file\": pdf_name,\n",
        "        \"text\": result.text_content\n",
        "    })\n",
        "\n",
        "    # print(\"=\" * 80)\n",
        "    # print(f\"ðŸ“„ {pdf_name}\")\n",
        "    # print(\"=\" * 80)\n",
        "    # print(result.text_content)\n",
        "    # print(\"\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VA2GvPWTQFt9"
      },
      "source": [
        "# Connect to our MCP server\n",
        "\n",
        "Documentation about MCP: https://modelcontextprotocol.io/docs/getting-started/intro.\n",
        "\n",
        "Using MCP servers in Langchain https://docs.langchain.com/oss/python/langchain/mcp."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mbkH9xHXfmK"
      },
      "source": [
        "## Check which tools that the MCP server provide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6h0311KbN9A3",
        "outputId": "bd613899-ed54-4b3f-a5ba-f67356ec3c67"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import json\n",
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "\n",
        "client = MultiServerMCPClient({\n",
        "    \"social_graph\": {\n",
        "        \"transport\": \"http\",\n",
        "        \"url\": \"https://ftec5660.ngrok.app/mcp\",\n",
        "        \"headers\": {\"ngrok-skip-browser-warning\": \"true\"}\n",
        "    }\n",
        "})\n",
        "\n",
        "mcp_tools = await client.get_tools()\n",
        "# for tool in mcp_tools:\n",
        "#     print(tool.name)\n",
        "#     print(tool.description)\n",
        "#     print(tool.args)\n",
        "#     print(\"\\n\\n------------------------------------------------------\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABoe2-qfXl7r"
      },
      "source": [
        "## A simple agent using tools from the MCP server\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtTjwFKhTKn3",
        "outputId": "6081ddc7-eb73-46bd-c3a0-445fe0b91bbe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
        "\n",
        "# ---------------------------\n",
        "# 1. Define a local tool\n",
        "# ---------------------------\n",
        "@tool\n",
        "def say_hello(name: str) -> str:\n",
        "    \"\"\"Say hello to a person by name.\"\"\"\n",
        "    return f\"Hello, {name}! ðŸ‘‹\"\n",
        "\n",
        "# ---------------------------\n",
        "# 2. Load MCP tools + merge\n",
        "# ---------------------------\n",
        "client = MultiServerMCPClient({\n",
        "    \"social_graph\": {\n",
        "        \"transport\": \"http\",\n",
        "        \"url\": \"https://ftec5660.ngrok.app/mcp\",\n",
        "        \"headers\": {\"ngrok-skip-browser-warning\": \"true\"}\n",
        "    }\n",
        "})\n",
        "\n",
        "mcp_tools = await client.get_tools()\n",
        "tools = mcp_tools + [say_hello]\n",
        "\n",
        "# ---------------------------\n",
        "# 3. Initialize Gemini (tool-enabled) or deepseek\n",
        "# ---------------------------\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.5-flash\",\n",
        "    api_key=GEMINI_VERTEX_API_KEY, # Ensure this key is set in Colab secrets\n",
        "    temperature=0,\n",
        "    vertexai=True\n",
        ")\n",
        "llm_with_tools = llm.bind_tools(tools)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_tool_by_name(tool_name: str):\n",
        "    for t in tools:\n",
        "        if t.name == tool_name:\n",
        "            return t\n",
        "search_linkedin_people = get_tool_by_name(\"search_linkedin_people\")\n",
        "get_linkedin_profile = get_tool_by_name(\"get_linkedin_profile\")\n",
        "search_facebook_users = get_tool_by_name(\"search_facebook_users\")\n",
        "get_facebook_profile = get_tool_by_name(\"get_facebook_profile\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhLeoXGrqesW",
        "outputId": "f41572ca-0528-4efa-c9b4-9b0bd8acbdb6"
      },
      "outputs": [],
      "source": [
        "# This block provides you some tests to get faminilar with our MCP server\n",
        "\n",
        "# # Test 1: Search Facebook users (exact match)\n",
        "# await tools[0].ainvoke({'q': \"Minh Pham\", 'limit': 5})\n",
        "\n",
        "# # Test 2: Search Facebook users (fuzzy match with typo)\n",
        "# await tools[0].ainvoke({'q': \"Alx Chn\", 'limit': 5, 'fuzzy': True})\n",
        "\n",
        "# # Test 3: Get Facebook profile\n",
        "# await tools[1].ainvoke({'user_id': 180})\n",
        "\n",
        "# # Test 4: Get Facebook mutual friends\n",
        "# await tools[2].ainvoke({'user_id_1': 123, 'user_id_2': 456})\n",
        "\n",
        "# # Test 5: Search LinkedIn people (exact match)\n",
        "# await tools[3].ainvoke({'q': \"Python\", 'location': \"Hong Kong\", 'limit': 5})\n",
        "\n",
        "# # Test 6: Search LinkedIn people (fuzzy match with typo)\n",
        "# await tools[3].ainvoke({'q': \"Minh Pham\", 'location': \"Beijing\", 'limit': 5, 'fuzzy': True})\n",
        "\n",
        "# # Test 7: Get LinkedIn profile\n",
        "# await tools[4].ainvoke({'person_id': 95})\n",
        "\n",
        "# Test 8: Get LinkedIn interactions\n",
        "# await tools[5].ainvoke({'person_id': 456})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "debug_enabled = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import fields\n",
        "import json\n",
        "from typing import List, Optional\n",
        "from langchain_core.messages import BaseMessage\n",
        "import re\n",
        "\n",
        "\n",
        "def safe_invoke(model, cls, input: str, config: dict = None, stop: list = None, retries: int = 3) -> str:\n",
        "    for attempt in range(1, retries + 1):\n",
        "        try:\n",
        "            response = model.invoke(input, config=config, stop=stop)\n",
        "            content = response.content.strip()\n",
        "            content = re.sub(r\"^```(?:json)?\\s*|\\s*```$\", \"\", content.strip())\n",
        "            data = json.loads(content)\n",
        "            field_names = {f.name for f in fields(cls)}\n",
        "            filtered_data = {k: v for k, v in data.items() if k in field_names}\n",
        "            missing = field_names - filtered_data.keys()\n",
        "            if missing:\n",
        "                raise ValueError(f\"Missing fields: {missing}\")\n",
        "            if debug_enabled:\n",
        "                print(f\"[safe_invoke] response: {json.dumps(filtered_data, indent=2, ensure_ascii=False)}\")\n",
        "            return filtered_data\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"[safe_invoke:{attempt}] JSON decode error: {str(e)}. Response content: {response.content}\")\n",
        "        except Exception as e:\n",
        "            print(f\"[safe_invoke:{attempt}] Error during LLM invocation: {str(e)}\")\n",
        "    return {f.name: None for f in fields(cls)}\n",
        "\n",
        "def describe_schema(cls):\n",
        "    lines = [\"Your response **must** be a JSON object with the following format:\"]\n",
        "    for f in fields(cls):\n",
        "        if f.name.startswith(\"template_\"):\n",
        "            continue\n",
        "        desc = f.metadata.get(\"description\", \"\")\n",
        "        lines.append(f'- {f.name} ({f.type.__name__}): {desc}')\n",
        "    if hasattr(cls, \"output_format\"):\n",
        "        lines.append(f\"Here is an example of the expected output format:{cls.output_format}\")\n",
        "    return \"\\n\".join(lines)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import TypedDict, List, Dict, Any, Optional, Annotated, operator\n",
        "\n",
        "class CVState(TypedDict):\n",
        "    cv_file: str\n",
        "    cv_text: str\n",
        "    cv_json: dict\n",
        "    report: Optional[str]\n",
        "\n",
        "    linkedin_id: int | None\n",
        "    facebook_id: int | None\n",
        "    linkedin_profile: Dict[str, Any] | None\n",
        "    facebook_profile: Dict[str, Any] | None\n",
        "    \n",
        "    discrepancies: Annotated[List[Dict[str, Any]], operator.add]\n",
        "\n",
        "    trust_score: Optional[float]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define response format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from dataclasses import dataclass, field\n",
        "\n",
        "@dataclass\n",
        "class OrganizeOutput:\n",
        "    # thought: str = field(metadata={\"description\": \"One sentence thought process.\"})\n",
        "    personal_info: dict = field(metadata={\"description\": \"Personal information including name, professional summary, and locations.\"})\n",
        "    education: List[dict] = field(metadata={\"description\": \"List of educational background entries, each containing institution, degree, and graduation year.\"})\n",
        "    experience: List[dict] = field(metadata={\"description\": \"List of work experience entries, each containing company, job title, period, and responsibilities.\"})\n",
        "    skills: List[str] = field(metadata={\"description\": \"List of skills.\"})\n",
        "\n",
        "    output_format = \"\"\"\n",
        "{\n",
        "  \"personal_info\": {\n",
        "    \"name\": <string>,\n",
        "    \"professional_summary\": <string>,\n",
        "    \"locations\": [\"<string>\", ...]\n",
        "  },\n",
        "  \"education\": [\n",
        "    {\n",
        "      \"institution\": <string>,\n",
        "      \"degree\": <string>,\n",
        "      \"graduation_year\": <string>\n",
        "    },\n",
        "    ...\n",
        "  ],\n",
        "  \"experience\": [\n",
        "    {\n",
        "      \"company\": \"<string>\",\n",
        "      \"job_title\": \"<string>\",\n",
        "      \"period\": \"<string>\",\n",
        "      \"responsibilities\": [\"<string>\", ...]\n",
        "    },\n",
        "    ...\n",
        "  ],\n",
        "  \"skills\": [\"<string>\", \"...\"],\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "@dataclass\n",
        "class SearchOutput:\n",
        "    thought: str = field(metadata={\"description\": \"One sentence thought process.\"})\n",
        "    id: str = field(metadata={\"description\": \"Candidate ID found from LinkedIn or Facebook.\"})\n",
        "\n",
        "    output_format = \"\"\"\n",
        "{\n",
        "  \"thought\": <string>,\n",
        "  \"id\": <string>\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "@dataclass\n",
        "class InvestigateOutput:\n",
        "    discrepancies: list[dict] = field(metadata={\"description\": \"Discrepancies found between CV and LinkedIn profile.\"})\n",
        "\n",
        "    output_format = \"\"\"\n",
        "{\n",
        "  \"discrepancies\": [\n",
        "    {\n",
        "      \"severity\": <string>,\n",
        "      \"reason\": <string>\n",
        "    },\n",
        "    ...\n",
        "  ]\n",
        "}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "async def search_candidates(cv_locations: list, cv_name: str, cv_industry: str) -> list:\n",
        "    all_candidates = {}\n",
        "    locations_to_search = cv_locations if cv_locations else [None]\n",
        "    for loc in locations_to_search:\n",
        "        try:\n",
        "            results = await search_linkedin_people.ainvoke({\n",
        "                \"q\": cv_name,\n",
        "                \"location\": loc,\n",
        "                \"industry\": cv_industry,\n",
        "                \"limit\": 10,\n",
        "                \"fuzzy\": True\n",
        "            })\n",
        "            \n",
        "            for cand in results:\n",
        "                all_candidates[cand['id']] = cand\n",
        "        except Exception as e:\n",
        "            print(f\"Error when search for '{cv_name}','{loc}': {e}\")\n",
        "            \n",
        "    return list(all_candidates.values())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define graph nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def organize_node(state: CVState):\n",
        "    print(\"[organize_node] Organizing CV information into structured format...\")\n",
        "    prompt = f\"\"\"\n",
        "You are a helpful assistant that extracts structured information from CV text.\n",
        "\n",
        "[Task]\n",
        "organize the following information from the CV text into structured JSON format\n",
        "\n",
        "[Extracted CV Text]\n",
        "{state[\"cv_text\"]}\n",
        "\n",
        "[Output Format]\n",
        "{describe_schema(OrganizeOutput)}\n",
        "\n",
        "[Warning]\n",
        "- For locations, if only exist country, just return country. If city and country are available, **Only** return city. DO NOT indicate \"(Hometown)\" or \"(Current Location)\". Just return location name.\n",
        "- You cannot leave any field empty.\n",
        "\"\"\"\n",
        "    response = safe_invoke(llm, OrganizeOutput, prompt)\n",
        "    return {\n",
        "        \"cv_json\": response\n",
        "    }\n",
        "\n",
        "async def search_node(state: CVState):\n",
        "    print(\"[search_node] Searching for LinkedIn and Facebook profiles...\")\n",
        "    cv = state[\"cv_json\"]\n",
        "    candidates = await search_candidates(\n",
        "        cv_locations=cv['personal_info'].get('locations', []),\n",
        "        cv_name=cv['personal_info']['name'],\n",
        "        cv_industry=cv['personal_info'].get('professional_summary', '').split()[0]\n",
        "    )\n",
        "    print(f\"[search_node] candidates for {cv['personal_info']['name']}: {candidates}\")\n",
        "    if not candidates:\n",
        "        print(f\"[search_node] No candidates found in search_node for {cv['personal_info']['name']}.\")\n",
        "        return {\"linkedin_id\": None, \"linkedin_profile\": None}\n",
        "    prompt = f\"\"\"\n",
        "You are a professional background check expert. Please compare the job seeker's CV information with the following list of candidates found on LinkedIn.\n",
        "\n",
        "[CV Information]\n",
        "Name: {cv['personal_info']['name']}\n",
        "Summary: {cv['personal_info'].get('professional_summary', 'None')}\n",
        "Locations: {', '.join(cv['personal_info'].get('locations', []))}\n",
        "\n",
        "[LinkedIn Search Results]\n",
        "{json.dumps(candidates, ensure_ascii=False, indent=2)}\n",
        "Please analyze which candidate is **MOST LIKELY** the job seeker.\n",
        "\n",
        "[Output Format]\n",
        "{describe_schema(SearchOutput)}\n",
        "\"\"\"\n",
        "    print(f\"[search_node] Prompt for candidate search:\\n{prompt}\")\n",
        "    response = safe_invoke(llm, SearchOutput, prompt)\n",
        "    target_id = response['id']\n",
        "    candidate_profile = await get_linkedin_profile.ainvoke({\"person_id\": target_id})\n",
        "    return {\"linkedin_id\": target_id, \"linkedin_profile\": candidate_profile}\n",
        "\n",
        "async def investigate_node(state: CVState):\n",
        "    print(\"[investigate_node] Investigating discrepancies between CV and LinkedIn profile...\")\n",
        "    linkedin_profile = state[\"linkedin_profile\"]\n",
        "    if linkedin_profile is None:\n",
        "        print(\"[investigate_node] No LinkedIn profile to investigate.\")\n",
        "        return {\"discrepancies\": [{\"severity\": \"high\", \"reason\": \"No LinkedIn profile found for investigation.\", \"penalty\": 0.6}], \"trust_score\": 0.4}\n",
        "    cv = state[\"cv_json\"]\n",
        "    prompt = f\"\"\"\n",
        "You are a professional background check expert. Please compare the job seeker's CV information with the LinkedIn profile information.\n",
        "[CV Information]\n",
        "{cv}\n",
        "[LinkedIn Profile Information]\n",
        "{linkedin_profile}\n",
        "[scoring criteria]\n",
        "Each cv credibility is scored between [0, 1]. 1.0 indicates perfect match and no discrepancies. 0.0 indicates major discrepancies. You need to identify all mismatches and deduct points according to the following rules:\n",
        "\n",
        "1. Core Resume Falsification (High, -0.3): The company listed on the CV does not exist on LinkedIn.\n",
        "2. Education Falsification (High, -0.3): The school or degree is seriously inconsistent.\n",
        "3. Exaggerated Job Title (Medium, -0.15): The CV states Senior/Director, but LinkedIn lists it as Junior/Parallel.\n",
        "4. Exaggerated Work Hours (Medium, -0.15): The work hours listed on the CV do not match those on LinkedIn.\n",
        "5. Overstated Skills (Low, -0.05): The core skills listed on the CV do not match those on LinkedIn.\n",
        "[Output Format]\n",
        "{describe_schema(InvestigateOutput)}\n",
        "\"\"\"\n",
        "    print(f\"[investigate_node] Prompt for investigation:\\n{prompt}\")\n",
        "    response = safe_invoke(llm, InvestigateOutput, prompt)\n",
        "    disparencies = response[\"discrepancies\"]\n",
        "    trust_score = 1.0\n",
        "    for d in disparencies:\n",
        "        severity = d.get(\"severity\", \"low\").lower()\n",
        "        if severity == \"high\":\n",
        "            trust_score -= 0.3\n",
        "        elif severity == \"medium\":\n",
        "            trust_score -= 0.15\n",
        "        elif severity == \"low\":\n",
        "            trust_score -= 0.05\n",
        "    trust_score = max(0.0, min(1.0, trust_score))\n",
        "    return {\n",
        "        \"discrepancies\": response[\"discrepancies\"],\n",
        "        \"trust_score\": trust_score\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "agent_builder = StateGraph(CVState)\n",
        "agent_builder.add_node(\"organize\", organize_node)\n",
        "agent_builder.add_node(\"search\", search_node)\n",
        "agent_builder.add_node(\"investigate\", investigate_node)\n",
        "agent_builder.add_edge(\"organize\", \"search\")\n",
        "agent_builder.add_edge(\"search\", \"investigate\")\n",
        "agent_builder.add_edge(\"investigate\", END)\n",
        "\n",
        "agent_builder.set_entry_point(\"organize\")\n",
        "agent_graph = agent_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inputs = [{\"cv_file\": cv[\"file\"], \"cv_text\": cv[\"text\"]} for cv in all_cvs]\n",
        "results = await agent_graph.abatch(inputs,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "def extract_cv_index(filename: str) -> int:\n",
        "    match = re.search(r'CV_(\\d+)\\.pdf', filename)\n",
        "    return int(match.group(1)) if match else -1\n",
        "\n",
        "results_sorted = sorted(\n",
        "    results,\n",
        "    key=lambda r: extract_cv_index(r[\"cv_file\"])\n",
        ")\n",
        "\n",
        "scores = [r[\"trust_score\"] for r in results_sorted]\n",
        "scores = [r[\"trust_score\"] for r in results]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqO99iOlq6mc"
      },
      "source": [
        "# Evaluation code\n",
        "\n",
        "In the test phase, you will be given 5 CV files with fixed names:\n",
        "\n",
        "    CV_1.pdf, CV_2.pdf, CV_3.pdf, CV_4.pdf, CV_5.pdf\n",
        "\n",
        "Your system must process these CVs and output a list of 5 scores,\n",
        "one score per CV, in the same order:\n",
        "\n",
        "    scores = [s1, s2, s3, s4, s5]\n",
        "\n",
        "Each score must be a float in the range [0, 1], representing the\n",
        "reliability or confidence that the CV is valid (or meets the task criteria).\n",
        "\n",
        "The ground-truth labels are binary:\n",
        "\n",
        "    groundtruth = [0 or 1, ..., 0 or 1]\n",
        "\n",
        "Each CV is evaluated independently using a threshold of 0.5:\n",
        "\n",
        "- If score > 0.5 and groundtruth == 1 â†’ Full credit\n",
        "- If score â‰¤ 0.5 and groundtruth == 0 â†’ Full credit\n",
        "- Otherwise â†’ No credit\n",
        "\n",
        "In other words, 0.5 is the decision threshold.\n",
        "\n",
        "- Each CV contributes equally.\n",
        "- Final score = (number of correct decisions) / 5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0TtL07airIqz"
      },
      "outputs": [],
      "source": [
        "# =====================================================\n",
        "#  Evaluation code\n",
        "# =====================================================\n",
        "\n",
        "def evaluate(scores, groundtruth, threshold=0.5):\n",
        "    \"\"\"\n",
        "    scores: list of floats in [0, 1], length = 5\n",
        "    groundtruth: list of ints (0 or 1), length = 5\n",
        "    \"\"\"\n",
        "    assert len(scores) == 5\n",
        "    assert len(groundtruth) == 5\n",
        "\n",
        "    correct = 0\n",
        "    decisions = []\n",
        "\n",
        "    for s, gt in zip(scores, groundtruth):\n",
        "        pred = 1 if s > threshold else 0\n",
        "        decisions.append(pred)\n",
        "        if pred == gt:\n",
        "            correct += 1\n",
        "\n",
        "    final_score = correct / len(scores)\n",
        "\n",
        "    return {\n",
        "        \"decisions\": decisions,\n",
        "        \"correct\": correct,\n",
        "        \"total\": len(scores),\n",
        "        \"final_score\": final_score\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J14ltXjPtaMF",
        "outputId": "9fadc305-9a5d-489c-bfe6-c8f1d60bb700"
      },
      "outputs": [],
      "source": [
        "# scores = ... # Your code should generate this list [0.2, 0.3, 0.4, 0.5, 0.6]\n",
        "groundtruth = [1, 1, 1, 0, 0] # Do not modify\n",
        "\n",
        "result = evaluate(scores, groundtruth)\n",
        "print(result)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "RRbStil_qkQc",
        "kCENjOq6owDd"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "ftec",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
